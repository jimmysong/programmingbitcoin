= Programming Bitcoin
:imagesdir: images

[[chapter_blocks]]

## Blocks

Transactions essentially transfer bitcoins from one party to another and are authorized by signatures. This definitely ensures that the sender actually authorized the transaction, but what if the sender sends the same amount to multiple people? This is called the double-spending problem and is so called because the owner of an output may try to spend the same output twice. How is the receiver to be assured that they actually received the amount?

This is where a major innovation of Bitcoin comes in with Blocks. Think of Blocks as a way to order transactions. By ordering transactions, a double-spend cannot happen as the transaction that happens later is not considered valid.

Now it would be really nice if we could order transactions one at a time, but that would require everyone to agree which transaction is supposed to be next and would cause a lot of overhead in coming to consensus. We can also order large batches of transactions, maybe once per day, but that wouldn't be very practical as the transactions would settle only once per day.

Bitcoin settles every 10 minutes in batches of transactions. These batches of transactions are what we call blocks. In this chapter we'll go through how to parse them and how to check what's called the proof of work.

### Headers vs Full Blocks

Blocks are batches of transactions and the block header is metadata about the block itself. It has the following fields:

* Version
* Previous Block
* Merkle Root
* Timestamp
* Bits
* Nonce

This is the metadata for every block. The nice thing is that each field is fixed length. Version is 4 bytes, Previous Block is 32 bytes, Merkle Root is 32 bytes, Timestamp is 4 bytes, Bits is 4 bytes and Nonce is 4 bytes. The headers therefore, take up exactly 80 bytes for each block. As of this writing there are roughly 520,000 blocks so that ends up being roughly 40 megabytes. The entire blockchain, on the other hand, is roughly 150 GB, so the headers are roughly .027% of the size. This ends up becoming an important design consideration when we look at Simplified Payment Verification in Chapter 10.

### Version

Version in normal software refers to a particular state. That is, a particular version reflects a particular set of features. For a block, this is similar, in the sense that the version field reflects what capabilities the software that produced the block is ready for. In the past this was used as a way to indicate a single feature that was ready. Version 2 meant that the software was ready for BIP0016, or pay-to-script-hash as described previously.

Unfortunately, this means that only one feature may be signaled on the network at a time. To alleviate this, the developers came up with BIP9, which allows up to 29 different features to be signaled at the same time. The way this works is discussed later in this chapter.

### Previous Block

All blocks have to point to the parent. This is why the data structure is called a block*chain*, because we have a linked list of blocks that go all the way back to what we call the Genesis Block. We will note here that the block actually ends in a bunch of 0's, which we discuss more during the proof-of-work section.

### Merkle Root

Merkle Roots will be discussed more in Chapter 11, but essentially encode all the ordered transactions in a nice 32 byte hash. We will discuss how this is important for SPV (simplified payment verification) clients and how they can use the merkle root along with data from the server to get a proof-of-inclusion.

### Timestamp

The timestamp is a Unix-style timestamp taking up 4 bytes. Unix timestamps simply encode the number of seconds since January 1, 1970. This timestamp is used in two places. The first for validating timestamp-based locktimes on transactions included and in calculating a new difficulty every 2016 blocks.

### Bits

Bits is a field that encodes the amount of work necessary in this block. This will be discussed more in the proof-of-work section.

### Nonce

Nonce stands for "number used only once" or n-once. This number is what is changed by miners when looking for proof-of-work.

### Proof of work

Proof of work is what secures a block. To understand what proof-of-work is, it's easiest to look at the hash of a block like this:

TODO: add a block hex

The double-sha256 of this block looks like this:

TODO: add a double-sha256 of the block

Now when we interpret this as a little-endian number it's actually quite small for a 256-bit number:

TODO: show number

We can calculate the probability of any random 256-bit number being this small. The probability of the first bit in a 256-bit number being 0 is 0.5. The first two bits, 0.25. The first three bits, 0.125 and so on. In this case, we have the first n bits, which is 0.5^70^ or about 1 in x.

Every block in Bitcoin must be below a certain *target*. Target is a relatively small 256-bit number that is computed directly from the bits field. Specifically, the formula for calculating the bits comes down to this:

TODO: image of the formula

target = coefficient * 2^(8*(exponent-3))^

In this case, the target, when computed with this formula is:

TODO: show target number

A valid proof of work is a hash of the block which, when interpreted as a little-endian integer is below the target number. Proof of work hashes are exceedingly rare and the process of mining is essentially the process of finding one of these hashes. To find a single proof-of-work with the above target, the network as a whole must calculate x hashes. To give this number some context, the best GPU miner in the world would need to run for 50,000 years on average to find a single proof of work.

#### Difficulty

Target is a bit hard to work with. We know that this is the number that the hash must be below, but as humans, it's hard to fathom the difference between a 180-bit number and a 190-bit number. The first is a thousand times smaller, but from looking at targets, it's not easy to contextualize.

To make different targets easier to compare, the concept of difficulty was born. Essentially, difficulty is inversely proportional to target to make comparisons easier. The specific formula is:

TODO: formula for difficulty

The difficulty on testnet when there haven't been any blocks found in 20 minutes resets to 1. This gives us context for how difficult mainnet is. Generally, the difficulty number can be thought of as how much more difficult mainnet is than testnet's easiest difficulty.

This is the number that gets shown in block explorers and bihgoit price charting services as difficulty is a much more intuitive way to understand what's going on in terms of effort required to create a new block.

#### Difficulty Adjustment

Every 2016 blocks, target/difficulty/bits are adjusted according to this formula:

TODO: formula for adjustment

The nice thing about this formula is that you only need the headers to calculate what the next block target should be. If the block doesn't have the correct bits, then we can safely reject that block.

Incidentally, because the formula only looks at the bits for the block right before it, the formula often results in a difficulty of 1 on testnet.

TODO: example for difficulty adjustment

### Checking that the Proof-of-Work is sufficient

Proof-of-work is simply the double-sha256 of the block header. If this number, interpreted as a little-endian integer is lower than the target, we have a valid proof-of-work. If not, the block is not valid. Note that this is very easy to check. All we need to calculate is a single double-sha256 to check. On the other hand, creating the proof-of-work is really difficult. We would need to calculate on average X number of double-sha256 hashes at a difficulty of Y. This is what we would call an asymmetric problem and the reason why proof-of-work is an effective way to measure that the block producer has expended a sufficient amount of energy.

There's a reason why this process is likened to mining. It takes roughly 2-90 tons of processing dirt and rock in order to find a single ounce of gold. In the same way, we have to process lots of numerical dirt and rock in order to find a proof-of-work. Proof-of-work is rare and uniformly distributed, making finding one just as difficult with one type of header versus another.

TODO add some more on PoW